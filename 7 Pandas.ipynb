{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DIR = r'c://Users//mirza//OneDrive//Desktop//Fakultet//Biological Data Analysis with Python//Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DIR, \"viperdb.csv\"))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jupyter has a nice integration with pandas, regarding df display\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we can also use a display function\n",
    "# more convenient for small things\n",
    "# e.g. centers the display properly\n",
    "# doesn't write \"Out\" to the console (might be more useful in other IDEs)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe()) # quick summary of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting an entire column from a DataFrame will give us a Series object.\n",
    "subunits = df['Subunits']\n",
    "print(type(subunits))\n",
    "print(subunits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits[55]) # 55 here is more like a key (from a dict), not like an index in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting an entire row from a DataFrame will also give us a Series object.\n",
    "record = df.loc[55]\n",
    "print(type(record))\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(record['Subunits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subunits = df['Subunits']\n",
    "print(type(subunits))\n",
    "print(subunits.dtype)\n",
    "print(subunits.name)\n",
    "print(len(subunits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits[:5]) # this is again slicing by name, not by index (can be names)\n",
    "print(subunits[10:20:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits[500]) # produces KeyError, not an IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.get(500)) # no error\n",
    "print(subunits.get(500, 888)) # if no value, return something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random value from a series\n",
    "print(subunits.sample())\n",
    "print(subunits.sample())\n",
    "print(subunits.sample(5)) # By default this is without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = subunits.values # convert series to numpy array\n",
    "print(type(array), array.dtype)\n",
    "print(array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or other formats...\n",
    "l = subunits.tolist()\n",
    "print(type(l), l[:5])\n",
    "\n",
    "d = subunits.to_dict()\n",
    "print(type(d), dict(list(d.items())[:5]))\n",
    "\n",
    "print(subunits.to_json()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... to dataframe\n",
    "display(subunits.to_frame().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.min(), subunits.max())\n",
    "print(subunits.idxmin(), subunits.idxmax()) # get index\n",
    "print(subunits[subunits.idxmax()]) # or value under specific index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.mean(), subunits.std())\n",
    "print(subunits.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.quantile(0)) # min value\n",
    "print(subunits.quantile(0.33)) # value 1/3 of the way from the minimum\n",
    "print(subunits.quantile(0.72)) \n",
    "print(subunits.quantile(1)) # max value\n",
    "print(subunits.quantile(0.5)) # median\n",
    "print(subunits.quantile()) # By default this the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subunits.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(subunits.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an actual copy (not a pointer) to avoid modifying the original\n",
    "subunits_copy = subunits.copy() \n",
    "print(subunits_copy[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subunits_copy[55] = 6\n",
    "print(subunits_copy[50:60])\n",
    "print(subunits[50:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations can be done on slices:\n",
    "subunits_copy[50:55] = 0\n",
    "print(subunits_copy[50:60])\n",
    "subunits_copy[50:55] = range(5)\n",
    "print(subunits_copy[50:60])\n",
    "subunits_copy[50:55] += 3\n",
    "print(subunits_copy[50:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new record\n",
    "subunits_copy[len(subunits)] = 699 # similar to adding a new record in the dictionary\n",
    "print(subunits_copy.tail())\n",
    "\n",
    "# Removing a record\n",
    "del subunits_copy[417]\n",
    "print(subunits_copy.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because 417 is a key/label (and NOT a positional index) - 417 no longer exists!\n",
    "print(subunits_copy[416], subunits_copy[418], subunits_copy[419])\n",
    "print(subunits_copy[417])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unless we explicitly make a copy, everything is made by reference\n",
    "old_value = subunits[55] # (at least the slices are; 'old_value' is not a reference)\n",
    "subunits[55] = 6\n",
    "display(df.loc[53:57])\n",
    "# even though we've taken subunits column from a df, it still changes the value in the original df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above warning is generated because `subunits` can be either a \"view\" or a complete copy of the column. If it is a view, changing it will change the original DataFrame it came from (`df`), as intended. But if it is a copy, then only the copy will change, and not `df`! Pandas does not guarantee whether a view or a copy will be returned when using the `[]` syntax, and thus assignment should be done with `.loc[]` or `.iloc[]` (or `.at[]` and `.iat[]`, but we don't discuss those here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper way to alter a DataFrame:\n",
    "df.loc[55, 'Subunits'] = old_value\n",
    "display(df.loc[53:57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is also appropriate, and won't change the original DataFrame (so no warning).\n",
    "subunits_copy[55] = 6\n",
    "display(df.loc[53:57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting is also implemented in pandas\n",
    "print((subunits + 103)[:3])\n",
    "print((subunits - 103)[:3])\n",
    "print((subunits * 3)[:3])\n",
    "print((subunits / 7)[:3])\n",
    "print((subunits // 7)[:3])\n",
    "print((subunits ** 2)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but series by default behaves like a dictionary (unlike numpy arrays)...\n",
    "a = subunits[3:6]\n",
    "b = subunits[-3:]\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print('*' * 20)\n",
    "print(a + b) \n",
    "# ... so adding them will make a new dictionary, instead of adding corresponding values\n",
    "# by adding value under a[3] (=780) with value under b[3] (=NaN), so 780+NaN=780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the indeces are different, we can mimic numpy behavior by dropping the index\n",
    "# reset_index() returns a copy, and now the indices do match.\n",
    "print(a.reset_index(drop = True) + b.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(a.reset_index()) # by default reset_index keeps the old index\n",
    "display(a.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a single data frame, columns have the same indeces so we can use vectorized operations\n",
    "avg_radiuses = (df['Inner Radius'] + df['Outer Radius']) / 2\n",
    "print(avg_radiuses[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_series = avg_radiuses <= df['Average Radius']\n",
    "print(boolean_series[:5])\n",
    "print(boolean_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boolean_series.all())\n",
    "print(boolean_series.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only 7 values where the radius is NOT <= to average radius\n",
    "print(subunits[~boolean_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data in DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['Subunits'].head()) # A Series\n",
    "display(df[['Family', 'Genus', 'Subunits']].head()) # A DataFrame\n",
    "display(df[['Subunits']].head()) # A DataFrame with a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can also be accessed as attributes.\n",
    "# But it wont't work with spaces and other symbols, so it's better to stick to the [] syntax.\n",
    "# (this is also why it is recommended to avoid spaces and special symbols in column names)\n",
    "print((df.Subunits == df['Subunits']).all()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting by positional indices instead of the keys/labels.\n",
    "display(df.iloc[5])\n",
    "display(df.iloc[5:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas's terminology is somewhat confusing. The word \"index\" typically refers to the labels/keys of the series/dataframe, which is distinct from their \"positional indices\" or \"positions\".\n",
    "\n",
    "Most of Pandas functionality (including most of the functions and operations we have seen) works with the actual index, not positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting by indices (labels) instead of positions\n",
    "display(df.loc[5])\n",
    "display(df.loc[5:8]) # Note that this includes 8!\n",
    "\n",
    "# As a rule, label slices are always inclusive of the end label (unlike regular Python indices),\n",
    "# while positional indices are not (exactly like regular Python indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc can access both rows and columns (individual and slices)\n",
    "display(df.loc[5, 'Subunits']) # Single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[5:7, 'Subunits']) # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[5, 'Subunits':'Outside SASA']) # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[5, :]) # Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[5:7, 'Subunits':'Outside SASA']) # DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same like series, values in a DF can be changed\n",
    "old_value = df.loc[5, 'Subunits']\n",
    "df.loc[5, 'Subunits'] = 5 ** 20\n",
    "print(df.loc[5])\n",
    "df.loc[5, 'Subunits'] = old_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding columns and rows works by assigning to non-existing labels (similar to Python's dictionaries).\n",
    "# The column is added at the end of the DF by default\n",
    "df['Average Radius V2'] = (df['Inner Radius'] + df['Outer Radius']) / 2\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated example\n",
    "def check_outliers(series, stds = 2.5):\n",
    "    return (series - series.mean()).abs() >= stds * series.std()\n",
    "    \n",
    "df['Is Outlier'] = check_outliers(df['Inner Radius']) | \\\n",
    "check_outliers(df['Outer Radius']) | \\\n",
    "check_outliers(df['Average Radius'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing an unwanted column from a DF\n",
    "del df['Average Radius V2']\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping a column in a DF\n",
    "# unlike del, can drop multiple, can return a copy (instead of deleting in place)\n",
    "# drops rows by default\n",
    "display(df.drop(['Title', 'Resolution'], axis = 'columns').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.drop(['Title', 'Resolution'], axis = 1).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.drop(columns=['Title', 'Resolution']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and removing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add a series or a dict as a row\n",
    "# If a key is missing (i.e. a column name), the value in that cell will be NA\n",
    "\n",
    "df.loc[len(df)] = {\n",
    "    'Entry ID': 'xxxx',\n",
    "    'Family': 'XXXX',\n",
    "    'Genus': 'XXXX',\n",
    "    'Title': 'Bla bla bla',\n",
    "    'Resolution': '11.111',\n",
    "    'Genome': 'dsDNA',\n",
    "    'T': '88',\n",
    "    'Subunits': 180,\n",
    "    'Inner Radius': 222,\n",
    "    'Outer Radius': 333,\n",
    "    'Average Radius': 250,\n",
    "    'Net Surface Charge': 1500,\n",
    "    'Outside SASA': 44444,\n",
    "    'Is Outlier': False,\n",
    "}\n",
    "\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rows from a DataFrame, you can just slice and replace the variable \n",
    "# (but note that it won't change the original DataFrame, if it's stored elsewhere).\n",
    "df = df.iloc[:419]\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop is an alternative \n",
    "# (this still won't change `df` - but see the 'inplace' flag in later examples):\n",
    "display(df.drop([416, 418]).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.index))\n",
    "print(df.index)\n",
    "print(df.index.dtype, len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all index values in one DF will be the same\n",
    "print(df['Inner Radius'].index)\n",
    "print(df['Subunits'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = df.iloc[55]\n",
    "print(type(record.index))\n",
    "print(record.index)\n",
    "print(record.index.dtype, len(record.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set our own index in a DF (using another column, e.g.)\n",
    "# If we are using a column from the DF, it has to have unique values\n",
    "entry_indexed_df = df.set_index('Entry ID')\n",
    "display(entry_indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we access rows using a string \"index\" (a key)\n",
    "print(entry_indexed_df.loc['1cwp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different options of accessing desired values\n",
    "print(entry_indexed_df['Family'][13:16])\n",
    "print('*' * 100)\n",
    "print(entry_indexed_df.loc['3fbm':'1cwp']['Family'])\n",
    "print('*' * 100)\n",
    "print(entry_indexed_df.loc['3fbm':'1cwp','Family'])\n",
    "print('*' * 100)\n",
    "print(entry_indexed_df['Family']['1cwp'])\n",
    "print('*' * 100)\n",
    "print(entry_indexed_df.loc['1cwp']['Family'])\n",
    "# or using iloc (positional index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized opertions still work regularly, as long as the keys correspond to eachother\n",
    "# (they will in the same DF)\n",
    "print((df['Inner Radius'] + df['Outer Radius']).head())\n",
    "print('*' * 100)\n",
    "print((entry_indexed_df['Inner Radius'] + entry_indexed_df['Outer Radius']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will not work if the index is different...\n",
    "print((entry_indexed_df['Inner Radius'] + df['Outer Radius']).sample(10)) # Indices don't match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are also an index...\n",
    "print(type(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access all datatypes of columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a new dataframe\n",
    "display(df.rename(columns = {'Inner Radius': 'IR', 'Outer Radius': 'OR', 'Average Radius': 'AR'}).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = lambda name: name.replace(' ', '_').lower()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# E.g.\n",
    "display(df.rename(columns = lambda name: name.replace(' ', '_').lower()).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename rows\n",
    "display(df.rename(index = {418: -1, 417: -2}).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Series and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([2, 3, 5, 7, 11])\n",
    "print(series)\n",
    "print('*' * 50)\n",
    "\n",
    "series = pd.Series([2, 3, 5, 7, 11], index = ['p1', 'p2', 'p3', 'p4', 'p5'])\n",
    "print(series)\n",
    "print('*' * 50)\n",
    "\n",
    "series = pd.Series({'p1': 2, 'p2': 3, 'p3': 5, 'p4': 7, 'p5': 11})\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys will be column names\n",
    "new_df = pd.DataFrame({'value': [2, 3, 5, 7, 11], 'is_big': [False, False, False, False, True]})\n",
    "display(new_df)\n",
    "\n",
    "# Forcing the right order\n",
    "new_df = pd.DataFrame({'is_big': [False, False, False, False, True], 'value': [2, 3, 5, 7, 11]}, columns = ['value', 'is_big'])\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way using a list of lists (or a list of tuples, e.g.)\n",
    "new_df = pd.DataFrame([[2, False], [3, False], [5, False], [7, False], [11, True]], columns = ['value', 'is_big'])\n",
    "display(new_df)\n",
    "\n",
    "new_df = pd.DataFrame([[2, False], [3, False], [5, False], [7, False], [11, True]], columns = ['value', 'is_big'],\n",
    "        index = ['p1', 'p2', 'p3', 'p4', 'p5'])\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using numpy array\n",
    "random_df = pd.DataFrame(np.random.randn(5, 3), columns = ['A', 'B', 'C'])\n",
    "display(random_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract back just the values as a numpy matrix\n",
    "data = random_df.values\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating over records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python way: for loop and indeces\n",
    "charge_sum = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    record = df.iloc[i]\n",
    "    charge_sum += record['Net Surface Charge']\n",
    "    \n",
    "print(charge_sum)\n",
    "print(charge_sum == df['Net Surface Charge'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas way: iterrows\n",
    "charge_sum = 0\n",
    "\n",
    "for index, record in df.iterrows():\n",
    "    charge_sum += record['Net Surface Charge']\n",
    "    \n",
    "print(charge_sum)\n",
    "print(charge_sum == df['Net Surface Charge'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option1():\n",
    "    \n",
    "    charge_sum = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        record = df.iloc[i]\n",
    "        charge_sum += record['Net Surface Charge']\n",
    "        \n",
    "    return charge_sum\n",
    "    \n",
    "def option2():\n",
    "    \n",
    "    charge_sum = 0\n",
    "\n",
    "    for index, record in df.iterrows():\n",
    "        charge_sum += record['Net Surface Charge']\n",
    "        \n",
    "    return charge_sum\n",
    "\n",
    "%timeit option1() # 3. this is a last resort\n",
    "%timeit option2() # 2. otherwise, use pandas builtin functions\n",
    "%timeit df['Net Surface Charge'].sum() # 1. when possible, use numpy functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over series (Python way)\n",
    "\n",
    "series = df['Net Surface Charge']\n",
    "\n",
    "charge_sum = 0\n",
    "\n",
    "for charge in series:\n",
    "    charge_sum += charge\n",
    "    \n",
    "print(charge_sum)\n",
    "print(charge_sum == series.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over series (Pandas way)\n",
    "charge_sum = 0\n",
    "\n",
    "for index, charge in series.iteritems():\n",
    "    charge_sum += charge\n",
    "    \n",
    "print(charge_sum)\n",
    "print(charge_sum == series.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying functions on records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reminder\n",
    "df['Resolution'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. we want to extract a resolution if it is numeric\n",
    "def parse_resolution(raw_resolution):\n",
    "    try:\n",
    "        return float(raw_resolution)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "        \n",
    "print(df['Resolution'].apply(parse_resolution).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the operation on the original DF\n",
    "df = pd.read_csv(os.path.join(DIR, 'viperdb.csv'))\n",
    "df['Resolution'] = df['Resolution'].apply(parse_resolution)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also focus on multiple columns (e.g.)\n",
    "def get_taxonomy(record):\n",
    "    try:\n",
    "        return '%s;%s;%s' % (record['Genome'].split()[0], record['Family'], record['Genus'])\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "df['Taxonomy'] = df.apply(get_taxonomy, axis = 1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not have a required vectorized operation, apply is the next most efficient way to process our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# applymap works element-wise\n",
    "# E.g.\n",
    "display(df[['Inner Radius', 'Outer Radius', 'Average Radius']].applymap(lambda x: 'Big' if x >= 200 else 'Small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More DataFrame stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.count()) # count of values other than NaN/NA/none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform math operations on the whole DF (column-wise)\n",
    "print(df.std())\n",
    "print(df.mean())\n",
    "print(df.median())\n",
    "print(df.quantile(0.7))\n",
    "print(df.min())\n",
    "print(df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very useful (sometimes) function\n",
    "display(df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Resolution'][:10])\n",
    "print(pd.isnull(df['Resolution'])[:10])\n",
    "print(pd.notnull(df['Resolution'])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Resolution'].dropna()[:10])\n",
    "print(df['Resolution'].fillna(0)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df.dropna().loc[4:7])\n",
    "display(df.fillna(0).loc[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. creating a boolean column whether the resolution is acceptable\n",
    "\n",
    "df['Good Resolution'] = df['Resolution'].fillna(10).between(0.5, 2)\n",
    "display(df[df['Good Resolution']]) # filter only the rows with good resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isnull is different (and usually better) than np.isnan\n",
    "# focus on the output...\n",
    "\n",
    "for value in [np.nan, 0, None, '']:\n",
    "    \n",
    "    for function, function_name in [(pd.isnull, 'pd.isnull'), (np.isnan, 'np.isnan')]:\n",
    "        try:\n",
    "            print('%s(%s) = %s' % (function_name, repr(value), str(function(value))))\n",
    "        except Exception as e:\n",
    "            print('%s(%s) raises a %s' % (function_name, repr(value), str(type(e))))\n",
    "    \n",
    "    print('*' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = df.set_index('Entry ID', drop = True)\n",
    "series = index_df['Subunits']\n",
    "\n",
    "# sort series\n",
    "print(series.sort_values().head(3))\n",
    "print('*' * 50)\n",
    "print(series.sort_values(ascending = False).head(3))\n",
    "print('*' * 50)\n",
    "print(series.sort_index().head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort DF\n",
    "display(index_df.sort_values('Genome').head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(index_df.sort_index().head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inplace operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, most operations return copies, and do not change the original DataFrame or Series.\n",
    "df_copy = df.copy()\n",
    "display(df_copy.rename(columns = {'Family': 'F', 'Genus': 'G'}).head(2))\n",
    "display(df_copy.head(2)) # actual df is not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace = True implements changes in the original DF\n",
    "df_copy.rename(columns = {'Family': 'F', 'Genus': 'G'}, inplace = True)\n",
    "display(df_copy.head(2))\n",
    "# we could also use:\n",
    "df_copy = df_copy.rename(...)\n",
    "# but the first one is more efficient cpu/RAM-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.sort_values('Entry ID', inplace = True)\n",
    "df_copy.set_index('Title', inplace = True)\n",
    "df_copy.drop(['Resolution', 'Genome'], axis = 1, inplace = True)\n",
    "df_copy.fillna(0, inplace = True)\n",
    "display(df_copy) # all changes have been implemented..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining of operations in Pandas\n",
    "\n",
    "(the hallmark of functional programming)\n",
    "\n",
    "(and one of the reasons why inplace=False by default - allows efficient chaining of operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "display(df.loc[340:348, ['Inner Radius', 'Average Radius']]\\\n",
    "        .fillna(0).div(df.loc[340:348, 'Outer Radius'], axis = 0)\\\n",
    "        .applymap(lambda x: 'Big' if x >= 0.75 else 'Small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DIR, 'my_records.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DIR, 'my_records.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DIR, 'my_records.csv.gz'), index = False, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas opens gzip files by default\n",
    "display(pd.read_csv(os.path.join(DIR, 'my_records.csv.gz')).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd.read_csv\n",
    "Has a lot of useful options. E.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- delimiter (sep = '\\t') for tab-separated data\n",
    "- true_values, false_values, na_values allows us to specify which values will be read as true, false, na\n",
    "- iterator option allows us to partially load (huge) data\n",
    "- There are a lot more options, see: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(pd.options.display.max_rows)\n",
    "pd.options.display.max_rows = 2\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.options.display.max_colwidth)\n",
    "pd.options.display.max_colwidth = 10\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.options.display.float_format) # takes a function\n",
    "pd.options.display.float_format = lambda value: '%.2f' % value\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might not want to change the global pandas settings...\n",
    "with pd.option_context('display.max_rows', 10):\n",
    "    # This option will only be set within this scope, and revert to the previous value upon exit.\n",
    "    display(df)\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read http://pandas.pydata.org/pandas-docs/stable/options.html for more options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
